Got you. Let’s nail down a hybrid that *actually ships* and doesn’t blow up everything you’ve already built.

I’ll lay this out like a build spec you can hand to “future you” or another dev.

---

## 0. Core Idea of the Hybrid

* **Keep** your current 16-question wizard (it works, it’s tested, it’s deterministic).
* **Add** an AI “Scope Assistant” that:

  * Reads the user’s answers as they go
  * Asks **micro follow-ups** only when needed
  * Expands / clarifies into a richer scope behind the scenes
  * Advises the user in plain language

The wizard remains the spine.
The AI assistant is the brain that grows around it.

---

## 1. High-Level Architecture

### Components

1. **Wizard UI (existing)**

   * Step-by-step questions
   * Progress bar
   * Simple form fields

2. **Scope State Store (new, small)**

   * Stores:

     * Raw wizard answers
     * AI-enriched scope
     * AI clarification logs

3. **RAG Service (existing)**

   * Your embeddings, documents, deck/HVAC material, etc.
   * Called by AI when it needs trade-specific facts.

4. **AI Scope Assistant Service (new)**

   * One endpoint the wizard calls after each step.
   * Uses the “adaptive, advisory” system prompt style we discussed.
   * Responsible for:

     * Interpreting the user answer
     * Inferring extra detail when possible
     * Deciding whether a micro follow-up is needed
     * Suggesting advice / options

---

## 2. Data Model

### 2.1. Wizard Answers Table (or JSON in a single row)

```ts
type WizardAnswer = {
  stepKey: string;           // e.g. "landscape.service_type"
  questionLabel: string;     // text of the wizard question
  rawAnswer: string;         // user's literal input/selection
  timestamp: string;
};

type WizardSession = {
  sessionId: string;
  service: "landscape" | "hvac" | "deck" | ...;
  answers: WizardAnswer[];
};
```

### 2.2. AI-Enriched Scope Object

This is what TUDAO eventually uses for smart contracts:

```ts
type ScopeDetail = {
  serviceType: string;              // "mowing", "mulch", "deck_build"
  locationDescription: string;      // "front yard + right side"
  dimensions: string | null;        // "approx 20x20", or null if unknown
  materials: string[];              // ["hardwood mulch", "PT lumber"]
  accessNotes: string | null;       // "narrow gate on left", etc.
  riskFlags: string[];              // ["slope", "near gas line"]
  codeOrPermitFlags: string[];      // ["permit_likely", "railings_required"]
  schedulePreference: string | null;
  budgetSensitivity: "low" | "medium" | "high" | null;
};
```

### 2.3. AI Log / Micro Q&A

```ts
type AiInteraction = {
  stepKey: string;                 // which wizard step triggered it
  userMessage: string;             // user’s answer from that step
  aiFollowupQuestion?: string;     // optional micro-question AI asked
  aiAdvice?: string;               // advisory line shown in UI
  aiInferredFields: Partial<ScopeDetail>;
};
```

---

## 3. Frontend UX Blueprint

### 3.1. Keep Wizard Layout

For each wizard step:

* Top: existing question (one of your 16)
* Middle: input (text, radio, dropdown, etc.)
* Bottom: **AI Assistant Box** (new)

AI Assistant Box behavior:

* After user submits the step, you show:

  * Short AI response:

    * Either:

      * a **micro follow-up question** about that specific step, or
      * a **brief advisory “tip”** confirming/clarifying their choice.
  * A recap of what the system has understood so far:

    * e.g., “So far I have: front yard mowing, one-time, easy access.”

You do **NOT** replace the wizard. You augment each step with:

> “Here’s what your choices mean and what I recommend.”

### 3.2. When AI Asks a Micro Follow-Up

Example:

* Wizard step: “What kind of landscaping service?” → user selects “mulch beds”.
* AI assistant:

  * “Do you already have mulch on site, or should we include delivering new mulch?”
* User can answer right below in a small chat input **specific to that step**.

You post that micro-answer to the same backend endpoint; AI updates the `ScopeDetail`.

---

## 4. Backend Flow (Step-by-Step)

I’ll describe this as a single HTTP cycle per wizard step.

### 4.1. User Completes Wizard Step N

Frontend:

```ts
await fetch("/api/wizard/answer", {
  method: "POST",
  body: JSON.stringify({
    sessionId,
    stepKey: "landscape.service_type",
    questionLabel: "What are we doing today?",
    rawAnswer: "mulch beds"
  })
});
```

### 4.2. Backend: Save Answer, Call AI Assistant

```ts
// 1) Append answer to WizardSession in DB
const session = await loadWizardSession(sessionId);
session.answers.push({ stepKey, questionLabel, rawAnswer, timestamp: new Date().toISOString() });
await saveWizardSession(session);

// 2) Load current AI-enriched scope (if any)
let scope = await loadScopeDetail(sessionId) || getEmptyScope();

// 3) Call AI Scope Assistant
const aiResponse = await callAiAssistant({
  nextField: stepKey,              // in hybrid, "nextField" = this stepKey
  currentScope: scope,
  userMessage: rawAnswer,
  ragSnippets: await queryRag(stepKey, rawAnswer)
});

// 4) Merge AI inferred fields
scope = { ...scope, ...aiResponse.interpretation.updated_fields };
await saveScopeDetail(sessionId, scope);

// 5) Save AI interaction log if you want
await logAiInteraction(sessionId, {
  stepKey,
  userMessage: rawAnswer,
  aiFollowupQuestion: aiResponse.question,
  aiAdvice: aiResponse.advice,
  aiInferredFields: aiResponse.interpretation.updated_fields
});

// 6) Return AI question/advice to frontend
return json({
  scopePreview: scope,
  aiQuestion: aiResponse.question,
  aiAdvice: aiResponse.advice
});
```

### 4.3. Frontend Renders AI Box

If `aiQuestion` exists and is not empty:

* Display micro follow-up under that step.
* Provide small input box.
* When user answers, hit `/api/wizard/ai_followup` which calls the same AI assistant again but with `userMessage = followup answer`, and `nextField = same stepKey` or a special `aiFollowup:<step>` key.

If only `aiAdvice` exists:

* Show it as a small “tip” text and move on.

---

## 5. RAG Integration (Preserving All Your Work)

Your existing RAG stays exactly where it is.

You only need a small helper:

```ts
async function queryRag(stepKey: string, userMessage: string) {
  // Example: filter by service from session + stepKey
  const service = stepKey.split(".")[0]; // "landscape", "deck", etc.
  const topic = stepKey.split(".")[1];   // "service_type", "size", etc.

  return await vectorSearch({
    service,
    topic,
    text: userMessage,
    limit: 3
  });
}
```

The AI Scope Assistant gets those `ragSnippets` and uses them to:

* Suggest right material types
* Call out code/permit constraints
* Offer best-practice tips

But again: **RAG NEVER controls the wizard order**.

---

## 6. AI Assistant Prompt (Hybrid-Specific Behavior)

You don’t need the full Flow Controller now. Instead:

* `nextField` = the wizard’s `stepKey`
* The assistant’s job on each call:

  1. Interpret the user’s answer for that step.
  2. Update scope fields if possible.
  3. Optionally ask 1 micro follow-up question OR give advice.
  4. Never step outside that step’s domain.

So you adapt the system prompt like this:

* Remove the part about “you don’t decide the next field” (the wizard is the field).
* Emphasize: “Your job is to enrich the scope based on this step, not change the flow.”

You already have 95% of this written from our earlier prompt.

---

## 7. Implementation Phases (So You Don’t Get Lost Again)

### Phase 1 — Minimal AI (1–2 days)

* Wire `/api/wizard/answer` to:

  * Save answer
  * Call AI assistant
  * Have AI only:

    * Interpret scope fields
    * Return **advice** (no micro follow-up yet)

UI: Show a simple advice box only.

### Phase 1.5 — Add Micro Follow-Ups (another 1–2 days)

* Allow AI to return an optional `question` string.
* If present, frontend shows follow-up input.
* `/api/wizard/ai_followup` endpoint merges that into scope as well.

### Phase 2 — Replace Wizard with Full Conversational Flow (optional, later)

* Once you’re comfortable, you can:

  * Remove the rigid UI
  * Use the full “Flow Controller” approach we outlined before
  * Same AI engine, same RAG, same scope store
  * Only the front-end and state machine change

By then, you’ll have a proven AI core.

---

## 8. Why This Blueprint Solves Your “Two Steps Forward, Three Back”

Because:

* State is **stored in the DB**, not in the model’s head.
* Flow is **controlled by the wizard**, not by RAG.
* AI is **constrained to enrich one step at a time**.
* All your RAG training is reused and safe.
* You get advisory, adaptive behavior **without ripping out what works**.

---

If you want, next step I can:

* Draft the **exact TypeScript handler functions** for `/api/wizard/answer` and `/api/wizard/ai_followup` tailored to Replit.
* Or design the **landscaping-specific mapping**: which of your 16 questions map to which `ScopeDetail` fields, and where AI adds the most value.
